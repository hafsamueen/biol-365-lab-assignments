{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bf7330f39c0d4446838ef3f336a21937",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Tutorial 2: Intro to pandas for data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "72d87c1527fd459ba807d18724f6b189",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 135,
      "ranges": [],
      "toCodePoint": 183,
      "type": "link",
      "url": "https://github.com/KeithGalli/pandas/tree/master"
     }
    ]
   },
   "source": [
    "This tutorial goes over how to use the pandas library for working with large sets of data. It is is adapted from Keith Galli's tutorial on pandas: https://github.com/KeithGalli/pandas/tree/master "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5a59e8c8687842b49472dbad253b6e5c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4dfb7627f56b4d05a788d562ee8917af",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## 2.1 Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8c9cc8ed7c5149648a5b165167db8db7",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "The pandas library allows us to work with two important types of data:\n",
    "1) **Series**: a one-dimensional labeled array holding data of any type. It's similar to a list, but each element has an associated label (or 'index') associated with it.\n",
    "2) **DataFrame**: a two-dimensional data structure array. You can think of it like a spreadsheet or table, with rows and columns. \n",
    "\n",
    "\\\n",
    "Start by importing the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "We can create a dataframe from any delimited, text-based file. Let's load the **pokemon_data.csv** file as a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c7ee42c87ccf45639f1cb7608c1ffef4",
    "deepnote_app_is_output_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 16,
     "pageSize": 10,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 536,
    "execution_start": 1693616473337,
    "is_output_hidden": false,
    "output_cleared": false,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#the 'sep' argument specifies the delimiter type. For tab-separated files, use '\\t'\n",
    "df = pd.read_table('pokemon_data.csv', sep=',') \n",
    "\n",
    "#to view our dataframe:\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view only the first or last N rows, use `df.head(N)` or `df.tail(N)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "da71c63bec3e482c9d7381a52e4239f0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "46bdb825f55743cf896251ab18e96383",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## 2.2 Viewing rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fe8c1eb6557f49c8a6814cb3d0897338",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Some basic commands for accessing specific data by row/column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cc928cfb8bc945e3aa47c2aba8ef7d79",
    "deepnote_app_is_output_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 40,
    "execution_start": 1693616473394,
    "is_output_hidden": false,
    "output_cleared": false,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#displaying data for one column (note that this returns a pandas series):\n",
    "df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e680ce08795b46ee9917a44da370d2bc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 255,
    "execution_start": 1693616473399,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#multiple columns (note the use of double square brackets):\n",
    "df[['#', 'Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#displaying data for one row:\n",
    "df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#multiple rows:\n",
    "df.loc[[4,5,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas, rows are referred to by **index**. By default it is numerical. More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Conditional filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ec0808270ac64990b89833b5b908b041",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "We can combine column/row indexing with **boolean** operators to filter specific rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2ab0144d650b4536a66733bef1d6e8ae",
    "deepnote_app_is_output_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 0,
     "pageSize": 10,
     "sortBy": [
      {
       "id": "Attack",
       "type": "desc"
      }
     ]
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 314,
    "execution_start": 1693616473423,
    "is_output_hidden": false,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df['Name']=='Magikarp'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire expression evaluates to \"the rows in `df` where the value in the `Name` column is equal to `Magikarp`\". \n",
    "\n",
    "Note that the `==` operator checks if two values are equal, and returns `True` if they do, `False` otherwise.\\\n",
    "Guide to comparison operators: https://www.w3schools.com/python/gloss_python_comparison_operators.asp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also chain together multiple boolean operators using **logical** operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cbf9d0cfb4f048a6903ec9b3aabc33d3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 278,
    "execution_start": 1693616473482,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filtering for multiple conditions:\n",
    "df.loc[(df['Attack']>100) & (df['Defense']<50)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, `&` is short for the `AND` operator: the statement inside the square brackets will only return `True` if both statements in the round brackets return `True`. Note that you have to group the individual statements in round brackets when using logical operators. \n",
    "\n",
    "Try replacing `&` with `|` (short for the `OR` operator) to see what happens. \n",
    "\n",
    "Finally, putting `~` in front of a boolean statement (the `NOT` operator) returns the opposite of the original result. So `~(df['Attack']>100)` will return `True` for all values 100 and below, and `False` for all values above 100. Note the extra round brackets. The `!=` operator can be used as a shorthand for 'not equal to' instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "492470b312744b96bbbadc0243bf8b22",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2e58eb4732be4192842e3b6be4cf01bb",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Exercise #1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8f98c7024637418a81770abd5780dfc6",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 46,
      "marks": {
       "bold": true
      },
      "toCodePoint": 60,
      "type": "marks"
     },
     {
      "fromCodePoint": 84,
      "marks": {
       "bold": true
      },
      "toCodePoint": 91,
      "type": "marks"
     }
    ]
   },
   "source": [
    "Filter and display the data from `df` of only Grass pokemon (Type 1 or Type 2) with HP > 50.\\\n",
    "Hint: you may need an extra set of round brackets to ensure correct order of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3da65c3f92084e0fae6be5d0e213997b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 326,
    "execution_start": 1693616473533,
    "output_cleared": false,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f476114412ad41c2aa42e422f12f74c5",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "027053a5360843c395ab7c0670463b65",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## 2.4 Modifying data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ca8279f182394359ba7095a42aaba812",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "In the previous sections, even though the output cells showed modified versions of `df`, we didn't actually make changes to the dataframe itself.\n",
    "\n",
    "To do so, we have to re-write the original dataframe with `df =` followed by the function/command. **Be very careful doing this**, because overwriting the original data may cause unintended consequences when trying to re-run your code. Often, it is better to use the `copy()` command when executing a new cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "new_df = new_df.loc[(new_df['Attack']>100) & (new_df['Defense']<50)] \n",
    "\n",
    "#we have changed new_df, so viewing it shows the filtered data:\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "Notice that the `df.copy()` syntax is similar to the string/list methods covered in Tutorial 1. Series and dataframe functions work the same way, where you specify the object before the function, and then the parameters of the function within the brackets. Here are some other useful examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "#dropping columns and rows:\n",
    "df2 = df2.drop('Legendary', axis=1) #the axis argument specifies column (1) or row (0)\n",
    "df2 = df2.drop([2, 3, 4], axis=0) #multiple columns or rows can be dropped by passing a list\n",
    "\n",
    "#sorting by column values:\n",
    "df2 = df2.sort_values(by='Type 1', ascending=False) #specifying ascending=False sorts in reverse order\n",
    "df2 = df2.sort_values(by=['Type 1', 'Type 2'], ascending=[False, True]) #multi-column sorting\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, operations that define a new column, or change an existing column, **will** modify the original dataframe. Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "de2fdece60a04a77912f5169abe1a9c4",
    "deepnote_app_is_output_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 26,
    "execution_start": 1693616473549,
    "is_output_hidden": false,
    "output_cleared": false,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "#creating a copy of an existing column\n",
    "df2['Name_copy'] = df2['Name']\n",
    "\n",
    "#adding 10 to every number in a numerical column (specifying an existing column --> it will overwrite the current data)\n",
    "df2['HP'] = df2['HP'] + 10\n",
    "\n",
    "#concatenating two text columns:\n",
    "df2['All_types'] = df2['Type 1'] + ' ' + df2['Type 2']\n",
    "\n",
    "#an example of using string methods\n",
    "#note that you must specify \"str\" as the data type, otherwise it thinks you are trying to split the column\n",
    "df2['first_name'] = df2['Name'].str.split(' ', expand=True)[0]\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "495f054c51a8496294da9ec0ed5c28b7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "44ee793b8a2646cd9a5a8c0b56be68f9",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Exercise #2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1362ee76bb3341e9920b2b5068f86e16",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 22,
      "marks": {
       "bold": true
      },
      "toCodePoint": 25,
      "type": "marks"
     },
     {
      "fromCodePoint": 53,
      "marks": {
       "bold": true
      },
      "toCodePoint": 59,
      "type": "marks"
     },
     {
      "fromCodePoint": 79,
      "marks": {
       "bold": true
      },
      "toCodePoint": 84,
      "type": "marks"
     }
    ]
   },
   "source": [
    "Read the documentation for `df.sum()`: \\\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html \n",
    "\n",
    "\n",
    "Using `df.sum()`, create a new column in `df` (or a copy of `df`) that shows the sum of all stats (all numerical columns) for all pokemon.\n",
    "\n",
    "Hint: pandas functions often have many optional parameters. If not specified, the default value is used (listed in the documentation). This exercise only requires one specified parameter within `df.sum()`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e4a4739518640efa90cb2a2905444c0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "24ee4b0ef1d943b1b30a532555c0ea19",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## 2.5 Aggregating statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "442f29070e5041a0b19f925f51956082",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 90,
      "marks": {
       "bold": true
      },
      "toCodePoint": 99,
      "type": "marks"
     },
     {
      "fromCodePoint": 103,
      "marks": {
       "bold": true
      },
      "toCodePoint": 111,
      "type": "marks"
     }
    ]
   },
   "source": [
    "The `df.groupby()` method splits the data based on a category, applies a function, and combines the results.\n",
    "\n",
    "The following is an example of calculating the number of pokemon of each Generation using `.groupby()` and `.count()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "353f389297e74a63bad0b5985bf20aa0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1693616473590,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df.groupby('Generation').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the resulting dataframe is automatically re-indexed by Generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b5607e38dbea4aefac24a88fb3a46b52",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "We can also specify a specific column to apply the function to. Can you guess what the following code does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "bffb64b4b5e64e6587094f711648c47b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 20,
    "execution_start": 1693616473591,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df.groupby('Generation')['HP'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that passing a single column returns a series and not a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "31cd9a06ce2d4cd1afaa5754c0724831",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 19,
      "marks": {
       "bold": true
      },
      "toCodePoint": 41,
      "type": "marks"
     }
    ]
   },
   "source": [
    "\\\n",
    "We can also create hierarchical groupings by passing a list of columns into `.groupby()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "95b2c13de85542e99d7ef1005304661c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 384,
    "execution_start": 1693616473601,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df.groupby(['Legendary','Generation'])[['Attack','Defense']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a949586ab9c54d649f025fbe6dbfe973",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9633463c0ef24d55bad0018cb06ec626",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Exercise #3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7517aba8255a420cb328fea2eadddb89",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 61,
      "marks": {
       "bold": true
      },
      "toCodePoint": 71,
      "type": "marks"
     },
     {
      "fromCodePoint": 115,
      "marks": {
       "bold": true
      },
      "toCodePoint": 123,
      "type": "marks"
     }
    ],
    "number": 3,
    "style": "decimal"
   },
   "source": [
    "Create a new dataframe that shows the total number of pokemon in each **Generation**, by each type (**Type 1**). There should only be **one** column for counts. \n",
    "\n",
    "\n",
    "Hints: \n",
    "1) The column specified for the `.count()` function is somewhat arbitrary, as long as it doesn't contain any NaN values. \n",
    "2) Remember that passing a single column to a function returns a series. To convert it to a dataframe, use `series.to_frame()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "93ee0fd606af45bab33002fa5ba9a8ba",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Combining data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code does the same grouping as in Exercise 3, but with two dataframes: one for **Type 1** counts and one for **Type 2** counts. \n",
    "\n",
    "There is also some additional formatting with `df.rename()` but you dont need to know the details for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.copy().rename({'#':'Type1_counts', 'Type 1':'Type'},axis=1)\n",
    "df_1 = df_1.groupby(['Generation','Type'])['Type1_counts'].count().to_frame()\n",
    "\n",
    "df_2 = df.copy().rename({'#':'Type2_counts', 'Type 2':'Type'},axis=1)\n",
    "df_2 = df_2.groupby(['Generation','Type'])['Type2_counts'].count().to_frame()\n",
    "\n",
    "display(df_1) #display() is like print(), if you want to show multiple dataframes\n",
    "display(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say I wanted to add the Type 1 and Type 2 counts from `df_1` and `df_2`. If they had the exact same sorted index, I could just use `df_1['T1_counts'] + df_2['T2_counts']` to return a series with the totals. However, not all Types are present in both dataframes, which makes matching up the rows tricky.\n",
    "\n",
    "The `df.join()` function solves this problem, as it matches up values by the labels of a given index or column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_1.join(df_2, on=['Generation', 'Type'], how='outer')\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `on=` parameter tells it the common index(es) or column(s) to join on. They have to be the same name in both dataframes, which is why I used `.rename()` earlier.\n",
    "\n",
    "\n",
    "The `how=` parameter is set to `outer` here, so it includes **all** index values (i.e. values that are present in `df_1` OR `df_2`). Specifying `inner` would only keep index values that are shared between both dataframes, while `left` and `right` would keep only values from `df_1` and `df_2` respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "From here, obtaining the total counts is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_3.copy()\n",
    "df_4 = df_4.fillna(0) #replaces NaN values with 0 to enable addition\n",
    "df_4['Counts'] = df_4['Type1_counts'] + df_4['Type2_counts']\n",
    "df_4 = df_4[['Counts']] #filtering for only the total counts column\n",
    "\n",
    "df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common reshaping function is `df.pivot()`. To use it on `df_4` we first need to use `df.reset_index()` which takes the current index columns `[Generation, Type]` and turns them into regular data columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = df_4.reset_index().pivot(index='Generation', columns='Type', values='Counts')\n",
    "df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.pivot()` function creates a new dataframe where the row and column labels are specified by the `index` and `columns` parameters respectively. The `values` parameter is the data to fill the new dataframe with. \n",
    "\n",
    "All three parameters must be columns from the original dataframe, which is why we used `.reset_index()`, which turns the current index into a column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Applying functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that there are many built-in functions for series and dataframes. However, we can also define our own functions and use them with `.apply()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function divides a value by 10 if it is greater than 10\n",
    "def div_10(x):\n",
    "    if x > 10:\n",
    "        return x/10\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df_5['Bug'].apply(div_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "Note that `series.apply()` takes a function that works on a **single value** and applies it to **each value in the series**. \n",
    "\n",
    "For `dataframe.apply()`, you must pass a function that works on a **series** (or list) to apply it to **each column of the dataframe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function divides each element in a series by the maximum value in the series\n",
    "def scale_max(col):\n",
    "    return col/col.max()\n",
    "\n",
    "df_5.apply(scale_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to use `.apply()` on rows instead of columns, you would specify `axis=1` in the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise #4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous examples didn't modify `df_5`, so it should still hold the original pokemon counts. \n",
    "\n",
    "Using `df.apply()`, create a new dataframe from `df_5` where all values are scaled as a **percentage** of the total values for each Generation.\\\n",
    "Hint: you can check your work by seeing if row values add up to 100. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f145a7987e9f46aba062c39d07105618",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## 2.9 Exporting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1396812d65cb4774a5fdfcb4b92a248f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "This concludes Tutorial 2. We will be using the dataframe from Exercise 4 in the next tutorial, so export it using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1a4214c633c94d4aab4c188f26545532",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 18,
    "execution_start": 1693616473667,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "YOUR_DATAFRAME.to_csv('YOUR_NAME_pokemon_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check that the output is correct (see Tutorial answers notebook) before exporting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "65d3620ffb834eb7af62f2fea99ecf01",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f145a7987e9f46aba062c39d07105618",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## 2.10 Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many pandas functions are not covered in this tutorial, but are commonly used in general data science tasks. Knowing these in detail is **not required**, although a couple may come up in the assignment. If they do, I will explicitly state which question(s) they apply to and link the appropriate examples & documentation. Most of the time, they are fairly intuitive and easy to figure out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and data types\n",
    "\n",
    "`df.len()` returns the number of rows for a dataframe.\\\n",
    "`df.columns` and `df.index` returns column and row names. \\\n",
    "`series.describe()` returns basic statistical measures of a series.\\\n",
    "`series.unique()` returns the unique values of a series.\\\n",
    "`df.dtypes` returns a series of the *type* of data in each column (int, string, etc)\n",
    "\n",
    "\n",
    "You can turn any series into a list with the `.to_list()` function.\\\n",
    "You can also convert series to different data types. For example, `.to_string()` converts all data in a series to string type, regardless of original type. Often needed to ensure the data type is compatible with a function. \n",
    "\n",
    "\n",
    "### Filtering\n",
    "\n",
    "`df.query()` is an alternate way of boolean indexing by column value.\\\n",
    "`df.select_dtypes()` can be used to filter for only columns of a specific data type.\n",
    "\n",
    "`series.drop_duplicates()` returns a series with duplicate rows removed, keeping the first occurence. `keep='last'` will keep the last occurence instead.\\\n",
    "`series.isin()` returns a series with only elements contained in a list.\\\n",
    "`series.where()` is a faster way of performing operations on a series based on a condition.\n",
    "\n",
    "\n",
    "\n",
    "Many string methods can be used on series to filter for conditions. These include `str.startswith()`, `str.endswith()`, and `str.contains()`.\n",
    "\n",
    "\n",
    "### Combining data\n",
    "\n",
    "`pd.merge()` is similar to `.join()`.\\\n",
    "`pd.concat()` enables joining rows instead of columns.\n",
    "\n",
    "\n",
    "### Reshaping \n",
    "\n",
    "This guide is useful for visualizing other types of data reshaping: https://pandas.pydata.org/docs/user_guide/reshaping.html#reshaping \\\n",
    "`df.stack()`, `df.unstack()`, `df.melt()`, and `df.explode()` are common.\n",
    "\n",
    "\n",
    "### Other libraries\n",
    "Most of the time, pandas is used alongside **NumPy**\n",
    "(https://numpy.org/doc/stable/user/quickstart.html#basic-operations). The NumPy library enables data manipulation of arrays, which is another data type. It also has some cool functions such as `np.random()` to generate random numbers and `np.arange()` to generate numerical series. "
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "ebbcdb50bc924f5aa914f86a7a36ccf4",
  "deepnote_persisted_session": {
   "createdAt": "2023-09-02T01:31:15.654Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
